{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "mOtNJGQS--kj"
      },
      "source": [
        "## Лабораторная №6. Выбор признаков\n",
        "## Задание\n",
        "* Реализуйте 3 метода выбора признаков: встроенный, обёртку и фильтрующий.\n",
        "* Примените реализованные методы на наборе данных SMS или castle-or-lock.\n",
        "* Выведите первые 30 признаков (слов), выбранные каждым методом.\n",
        "* Сравните полученные списки с любыми тремя библиотечными методами, отличными от реализованных вами. В этом пункте не обязательно брать один метод обёртку, один встроенный и один фильтрующий.\n",
        "* Определите, как меняется качество работы различных (не менее трёх) классификаторов до и после выбора признаков каждым из методов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kjrf9c2l--ko"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2, f_classif\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYQ_03M5--kq"
      },
      "source": [
        "# Data\n",
        "\n",
        "1. Считываем файл 'SMS.tsv' в переменную 'data' с использованием разделителя '\\t' (табуляция).\n",
        "2. Создаем переменную 'Y', которая содержит закодированные с помощью one-hot encoding значения столбца 'class'. Значения 'ham' закодированы как 1, а все остальные значения (обычно 'spam') закодированы как 0.\n",
        "3. Создаем переменную 'X', которая содержит значения столбца 'text' после применения функции 'preprocesstext'. Функция 'preprocesstext' выполняет предобработку текста, такую как удаление лишних пробелов и символов и приводит весь текст к нижнему регистру.\n",
        "4. Скачиваем стоп-слова для английского языка из библиотеки NLTK.\n",
        "5. Инициализируем TF-IDF векторизатор 'tfid' с максимальным количеством признаков равным 2000 и заданными стоп-словами.\n",
        "6. Преобразует переменную 'X' с помощью TF-IDF векторизатора 'tfid', сохраняя результаты в переменную 'X'.\n",
        "\n",
        "Таким образом, этот код выполняет предобработку текста и векторизацию с использованием TF-IDF для дальнейшего использования в задаче классификации спама и не спама в SMS-сообщениях.\n",
        "\n",
        "(TF-IDF (Term Frequency-Inverse Document Frequency) векторизатор используется для преобразования текстовых документов в числовые вектора, которые можно использовать для обучения моделей машинного обучения или для анализа текста. Он представляет каждый документ как вектор, где каждая компонента вектора соответствует какому-либо термину или слову. TF-IDF учитывает как важность термина внутри документа (частота термина в документе), так и его важность внутри коллекции документов (обратная частота термина в коллекции). Это позволяет отличить важные термины, которые встречаются часто в данном документе, от общих терминов, которые встречаются часто во всей коллекции.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1EmbA55--kr",
        "outputId": "152c4147-c1cc-4e21-c3d7-204df3e183e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "def preprocess_text(text):\n",
        "    result = ''\n",
        "    for char in text:\n",
        "        if char.isalpha() or char.isspace():\n",
        "            result += char\n",
        "    result = ' '.join(result.split())\n",
        "    return result.lower()\n",
        "\n",
        "data = pd.read_csv('data/SMS.tsv', delimiter='\\t')\n",
        "X, Y = data.text.map(preprocess_text), pd.get_dummies(data['class']).ham\n",
        "\n",
        "nltk.download('stopwords')\n",
        "tfid = TfidfVectorizer(max_features=2000, stop_words=stopwords.words('english'))\n",
        "X = tfid.fit_transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgkvcxJX--ks"
      },
      "source": [
        "# Embedded method\n",
        "\n",
        "1. Обучаем модель RandomForestClassifier на входных данных X и Y.\n",
        "2. Вычисляем важности признаков, полученные от обученной модели Random Forest, с помощью метода featureimportances.\n",
        "3. Получаем список всех признаков с помощью метода getfeaturenamesout() объекта tfid.\n",
        "4. Сортируем список признаков по убыванию их важности, используя важности признаков в качестве ключа для сортировки.\n",
        "5. Фильтруем список признаков, оставляя только те признаки, чья важность превышает среднюю важность всех признаков.\n",
        "6. Сохраняем результат в переменную selectedfeatures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pmGTami--kt",
        "outputId": "c525d4ec-3a28-4701-e5c0-8c76e77cc4e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "315 2000\n"
          ]
        }
      ],
      "source": [
        "clf = RandomForestClassifier().fit(X, Y)\n",
        "feature_importance = clf.feature_importances_\n",
        "features = tfid.get_feature_names_out()\n",
        "\n",
        "mean_importance = np.mean(feature_importance)\n",
        "embedded_method = [feature for feature, importance in sorted(zip(features, feature_importance), key=lambda x: x[1], reverse=True) if importance > mean_importance]\n",
        "\n",
        "print(len(embedded_method), len(features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpw7vgeP--kt"
      },
      "source": [
        "# Wrapper method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "O20M2rX6--kt",
        "outputId": "04741086-e5b2-4c15-a2b4-15f0e10dc3e8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
            "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
            "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
            "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
            "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
            "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
            "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
            "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n"
          ]
        }
      ],
      "source": [
        "# Используем функцию `train_test_split` из библиотеки `sklearn.model_selection`,\n",
        "# чтобы разделить данные на обучающий набор (`X_train`, `Y_train`) и\n",
        "# тестовый набор (`X_test`, `Y_test`). Тестовый набор составляет 20% от исходного набора данных.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "X_tr, X_ts = X_train.toarray(), X_test.toarray()\n",
        "\n",
        "# Определяем функцию `get_matrix`, которая принимает матрицу `m` и список столбцов `col`,\n",
        "# и возвращает новую матрицу, содержащую только выбранные столбцы из исходной матрицы.\n",
        "def get_matrix(m, col):\n",
        "    return [[vec[j] for j in col] for vec in m]\n",
        "\n",
        "best_accuracy, best_features = 0.0, []\n",
        "\n",
        "# Создаем модель `GaussianNB` с помощью которой будем обучать и предсказывать наши данные.\n",
        "model = GaussianNB()\n",
        "\n",
        "# Будем итерироваться циклом пока не получим 30 признаков.\n",
        "while len(best_features) < 30:\n",
        "    current_features = best_features.copy()\n",
        "    # Перебираем все признаки\n",
        "    for k in range (len(features)):\n",
        "        # Для каждого признака проверяем, если его индекс (`k`) не содержится в лучших признаках.\n",
        "        if k in best_features:\n",
        "            continue\n",
        "        # Копируем в новый список текущий список лучших признаков, и добавляем индекс текущего признака.\n",
        "        vector = current_features.copy() + [k]\n",
        "        # Обучаем `GaussianNB` на основе полученной матрицы из вектора и X_tr, и `Y_train`.\n",
        "        # model = GaussianNB()\n",
        "        model.fit(get_matrix(X_tr, vector), Y_train)\n",
        "        # Предсказываем на основе полученной матрицы из вектора и X_ts.\n",
        "        Y_pred = model.predict(get_matrix(X_ts, vector))\n",
        "        # Вычисляем точность прогнозов, сравнивая их с фактическими значениями из тестового набора.\n",
        "        current_accuracy = accuracy_score(Y_test, Y_pred)\n",
        "        # Берем признаки с лучшей точностью.\n",
        "        if current_accuracy > best_accuracy:\n",
        "            best_accuracy = current_accuracy\n",
        "            best_features = vector\n",
        "        # print(k, best_features, len(best_features), best_accuracy)\n",
        "\n",
        "# берем признаки\n",
        "wrapped_method = [features[k] for k in best_features]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDBqh0vG--ku"
      },
      "source": [
        "# Filter method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkMZjgRI--kv"
      },
      "outputs": [],
      "source": [
        "filtered, features_indexes = [], []\n",
        "\n",
        "# матрица коэффициентов корреляции между всеми парами признаков в Х.\n",
        "matrix = abs(np.corrcoef(X.toarray(), rowvar=False))\n",
        "\n",
        "# проитерируемся по всем элементам матрицы которые превышают среднее значение всех элементов матрицы, для фильтрации только значимах корреляций\n",
        "for p in np.argwhere(matrix > matrix.flatten().mean()):\n",
        "    i, j = tuple(p)\n",
        "    # Если i и j равны, то это значит, что признак коррелирует с самим собой и он пропускается.\n",
        "    # Если i не содержится в features_fl и не содержится в filtered,\n",
        "    # то он добавляется в features_fl. j добавляется в filtered.\n",
        "    if i == j:\n",
        "        continue\n",
        "    if i not in features_indexes and i not in filtered:\n",
        "        features_indexes += [i]\n",
        "        filtered += [j]\n",
        "\n",
        "# Список признаков, которые не были удалены на основе коэффициента корреляции с фильтрацией.\n",
        "filtered_method = [features[i] for i in range(len(features)) if i not in filtered]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "GGvvhqma--kv"
      },
      "source": [
        "# Вводим первые 30 признаков из каждого метода."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzkY5Gx---kv",
        "outputId": "5894a0ea-82a3-497a-835d-31107e912f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['call', 'free', 'txt', 'claim', 'mobile', 'stop', 'text', 'prize', 'reply', 'urgent', 'win', 'nokia', 'service', 'customer', 'tone', 'contact', 'chat', 'ppm', 'box', 'ringtone', 'guaranteed', 'cash', 'awarded', 'pmin', 'new', 'tcs', 'pobox', 'per', 'apply', 'draw']\n",
            "['txt', 'claim', 'mobile', 'box', 'pobox', 'nokia', 'points', 'admirer', 'delivery', 'texts', 'urgent', 'bak', 'ltgt', 'charge', 'service', 'apply', 'mail', 'currently', 'services', 'starts', 'tc', 'welcome', 'accidentally', 'always', 'chat', 'also', 'amazing', 'awaiting', 'award', 'cam']\n",
            "['aiyah', 'appreciate', 'argue', 'argument', 'arms', 'arrested', 'asap', 'asks', 'asleep', 'assume', 'ate', 'attend', 'bag', 'bahamas', 'bak', 'balance', 'barely', 'basic', 'basically', 'bath', 'bathe', 'bathing', 'battery', 'bay', 'bcums', 'bday', 'becoz', 'bed', 'bedroom', 'beer']\n"
          ]
        }
      ],
      "source": [
        "print(embedded_method[:30])\n",
        "print(wrapped_method)\n",
        "print(filtered_method[:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "AJeMpRs---kw"
      },
      "source": [
        "# Сделаем все то же самое с библиотечными методами выбора признаков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ln6mGLDS--kw",
        "outputId": "cc266ad8-310d-43f4-dd1e-56241a8eef1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ac' 'account' 'action' 'admirer' 'age' 'alert' 'ampm' 'announcement'\n",
            " 'anytime' 'apply' 'arcade' 'arrive' 'attempt' 'auction' 'await'\n",
            " 'awaiting' 'award' 'awarded' 'bid' 'bluetooth' 'bonus' 'box'\n",
            " 'btnationalrate' 'bx' 'call' 'caller' 'camcorder' 'camera' 'cash'\n",
            " 'cashbalance']\n"
          ]
        }
      ],
      "source": [
        "# Создаем объект модели SelectKBest с использованием метода chi2\n",
        "# и задаем параметр, чтобы выбрать 300 наиболее значимых признаков.\n",
        "# Обучаем модель на наборе данных и выводим первые 30 признаков.\n",
        "model = SelectKBest(chi2, k=300)\n",
        "model.fit(X, Y)\n",
        "print(features[model.get_support()][:30])\n",
        "\n",
        "# Преобразуем данные X с использованием выбранных признаков и сохраняем результат.\n",
        "X_chi2 = model.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSsjlUwg--kw",
        "outputId": "2b015e74-0af7-496e-ffed-93241c83cb37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ac' 'access' 'admirer' 'age' 'apply' 'attempt' 'award' 'awarded' 'bid'\n",
            " 'box' 'call' 'camera' 'cant' 'cash' 'charity' 'chat' 'choose' 'claim'\n",
            " 'club' 'code' 'collect' 'collection' 'come' 'congrats' 'contact'\n",
            " 'content' 'cost' 'credits' 'currently' 'customer']\n"
          ]
        }
      ],
      "source": [
        "# Создаем объект модели SelectFromModel с использованием модели LogisticRegression с параметрами penalty=\"l1\", dual=False и solver='liblinear'.\n",
        "# Обучает модель на наборе данных и выводим первые 30 признаков.\n",
        "model = SelectFromModel(LogisticRegression(penalty=\"l1\", dual=False, solver='liblinear').fit(X, Y), prefit=True)\n",
        "print(features[model.get_support()][:30])\n",
        "\n",
        "# Преобразует данные X с использованием выбранных признаков и сохраняет результат.\n",
        "X_reg = model.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B0a7M3S--kx",
        "outputId": "54b79e16-0e47-4f9e-c140-38a1a0fa84fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['account' 'admirer' 'ae' 'age' 'ampm' 'announcement' 'ansr' 'apply'\n",
            " 'attempt' 'auction' 'await' 'awaiting' 'award' 'awarded' 'bluetooth'\n",
            " 'bonus' 'box' 'btnationalrate' 'bx' 'call' 'caller' 'camcorder' 'camera'\n",
            " 'cash' 'cashbalance' 'cashin' 'cc' 'cd' 'cds' 'chance']\n"
          ]
        }
      ],
      "source": [
        "# Создаем объект модели SelectKBest с использованием метода f_classif\n",
        "# и задаем параметр, чтобы выбрать 300 наиболее значимых признаков.\n",
        "# Обучаем модель на наборе данных и выводим первые 30 признаков.\n",
        "model = SelectKBest(f_classif, k=300)\n",
        "model.fit(X, Y)\n",
        "print(features[model.get_support()][:30])\n",
        "\n",
        "# Преобразует данные X с использованием выбранных признаков и сохраняет результат.\n",
        "X_f_classif = model.transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Cnuy8eQj--kx"
      },
      "source": [
        "# Разбиваем данные на тренировочный и тестовый наборы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayB6ssCm--kx"
      },
      "outputs": [],
      "source": [
        "X_ = pd.DataFrame(X.toarray(), columns=features)\n",
        "X_chi2_train, X_chi2_test, y_train, y_test = train_test_split(X_chi2, Y, test_size=0.2, random_state=42)\n",
        "X_reg_train, X_reg_test, y_train, y_test = train_test_split(X_reg, Y, test_size=0.2, random_state=42)\n",
        "X_f_train, X_f_test, y_train, y_test = train_test_split(X_f_classif, Y, test_size=0.2, random_state=42)\n",
        "X_emb_train, X_emb_test, y_train, y_test = train_test_split(X_[embedded_method], Y, test_size=0.2, random_state=42)\n",
        "X_wr_train, X_wr_test, y_train, y_test = train_test_split(X_[wrapped_method], Y, test_size=0.2, random_state=42)\n",
        "X_fm_train, X_fm_test, y_train, y_test = train_test_split(X_[filtered_method], Y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "TZOyNXeL--ky"
      },
      "source": [
        "# Определим, как меняется качество работы различных (не менее трёх) классификаторов до и после выбора признаков каждым из методов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNX8Zm-R--ky",
        "outputId": "966ee5de-50db-403a-ef07-0fa1058cb939"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "default: 0.8663677130044843\n",
            "chi2: 0.95695067264574\n",
            "l1-based selection: 0.9533632286995516\n",
            "f-test: 0.957847533632287\n",
            "random forest: 0.9560538116591928\n",
            "Bayes wrapper: 0.905829596412556\n",
            "correlation: 0.9632286995515695\n"
          ]
        }
      ],
      "source": [
        "# Logistic Regression\n",
        "\n",
        "models = {\n",
        "    'default': (X_train, X_test),\n",
        "    'chi2': (X_chi2_train, X_chi2_test),\n",
        "    'l1-based selection': (X_reg_train, X_reg_test),\n",
        "    'f-test': (X_f_train, X_f_test),\n",
        "    'random forest': (X_emb_train, X_emb_test),\n",
        "    'Bayes wrapper': (X_wr_train, X_wr_test),\n",
        "    'correlation': (X_fm_train, X_fm_test)\n",
        "}\n",
        "\n",
        "for model_name, (X_train, X_test) in models.items():\n",
        "    accuracy = accuracy_score(y_test, LogisticRegression().fit(X_train, y_train).predict(X_test))\n",
        "    print(f'{model_name}: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FA-BVX3J--ky",
        "outputId": "c58095ca-9788-4dc9-9e3f-57a02a43b53d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "default: 0.9246636771300448\n",
            "chi2: 0.9381165919282511\n",
            "l1-based selection: 0.9542600896860987\n",
            "f-test: 0.9381165919282511\n",
            "random forest: 0.9345291479820628\n",
            "Bayes wrapper: 0.9623318385650225\n",
            "correlation: 0.9246636771300448\n"
          ]
        }
      ],
      "source": [
        "# KNN\n",
        "\n",
        "models = {\n",
        "    'default': (X_train, X_test),\n",
        "    'chi2': (X_chi2_train, X_chi2_test),\n",
        "    'l1-based selection': (X_reg_train, X_reg_test),\n",
        "    'f-test': (X_f_train, X_f_test),\n",
        "    'random forest': (X_emb_train, X_emb_test),\n",
        "    'Bayes wrapper': (X_wr_train, X_wr_test),\n",
        "    'correlation': (X_fm_train, X_fm_test)\n",
        "}\n",
        "\n",
        "for model_name, (X_train, X_test) in models.items():\n",
        "    accuracy = accuracy_score(y_test, KNeighborsClassifier().fit(X_train, y_train).predict(X_test))\n",
        "    print(f'{model_name}: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYHCJgin--ky",
        "outputId": "1340ca5b-ff33-4da9-b4e3-cabb1e1f585e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "default: 0.9623318385650225\n",
            "chi2: 0.9623318385650225\n",
            "l1-based selection: 0.9668161434977578\n",
            "f-test: 0.9650224215246637\n",
            "random forest: 0.9533632286995516\n",
            "Bayes wrapper: 0.9596412556053812\n",
            "correlation: 0.957847533632287\n"
          ]
        }
      ],
      "source": [
        "# Decision tree\n",
        "\n",
        "models = {\n",
        "    'default': (X_train, X_test),\n",
        "    'chi2': (X_chi2_train, X_chi2_test),\n",
        "    'l1-based selection': (X_reg_train, X_reg_test),\n",
        "    'f-test': (X_f_train, X_f_test),\n",
        "    'random forest': (X_emb_train, X_emb_test),\n",
        "    'Bayes wrapper': (X_wr_train, X_wr_test),\n",
        "    'correlation': (X_fm_train, X_fm_test)\n",
        "}\n",
        "\n",
        "for model_name, (X_train, X_test) in models.items():\n",
        "    accuracy = accuracy_score(y_test, DecisionTreeClassifier().fit(X_train, y_train).predict(X_test))\n",
        "    print(f'{model_name}: {accuracy}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}